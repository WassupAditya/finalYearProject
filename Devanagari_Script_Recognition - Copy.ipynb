{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d09805c",
   "metadata": {
    "id": "5d09805c"
   },
   "source": [
    "### Import all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sYEGc9fCcoTE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sYEGc9fCcoTE",
    "outputId": "6f4fcdc0-5da9-420e-9ac1-1be46fe6ddec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras_preprocessing\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "     ---------------------------------------- 0.0/42.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.6/42.6 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\sndes\\anaconda3\\lib\\site-packages (from keras_preprocessing) (1.24.3)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\sndes\\anaconda3\\lib\\site-packages (from keras_preprocessing) (1.16.0)\n",
      "Installing collected packages: keras_preprocessing\n",
      "Successfully installed keras_preprocessing-1.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install keras_preprocessing\n",
    "# pip install keras\n",
    "# pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "189b315c",
   "metadata": {
    "id": "189b315c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense,Conv2D, MaxPool2D,Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Sequential, Model\n",
    "from keras_preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras.applications import ResNet152V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6f6cc2a",
   "metadata": {
    "id": "f6f6cc2a"
   },
   "outputs": [],
   "source": [
    "img=load_img(r\"C:\\Users\\sndes\\JupyterProjects\\FinalProject\\Fin_DS - Copy\\train\\क\\5_क.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3a9e813",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3a9e813",
    "outputId": "ef0afbc0-b022-445a-959e-8484489b6b42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.Image.Image"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b0711ac",
   "metadata": {
    "id": "1b0711ac"
   },
   "outputs": [],
   "source": [
    "img=img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97bc009d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "97bc009d",
    "outputId": "da77685e-c98f-439b-ab73-2bb4ca59d6db"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x182ab790ad0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "001113a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "001113a8",
    "outputId": "3f8e9971-21e5-4e62-8fd3-709d51c1a0fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0f3f5a",
   "metadata": {
    "id": "0d0f3f5a"
   },
   "source": [
    "### Build the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e941588",
   "metadata": {
    "id": "0e941588"
   },
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(32, input_shape=(64,64,3), kernel_size=(3,3),\n",
    "                 activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(32,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(51,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9df347a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9df347a",
    "outputId": "af84f6ac-e65e-46ae-83ad-ebe8573ed660"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 31, 31, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 14, 14, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               3211776   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 51)                26163     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3248083 (12.39 MB)\n",
      "Trainable params: 3248083 (12.39 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a98284",
   "metadata": {
    "id": "a9a98284"
   },
   "source": [
    "### Visualize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d44c34e3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 812
    },
    "id": "d44c34e3",
    "outputId": "3bfe9c7c-cf65-4b29-a132-207d23fe9e2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, show_dtype=True, show_layer_names=True, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db15cbef",
   "metadata": {
    "id": "db15cbef"
   },
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2c705c7",
   "metadata": {
    "id": "a2c705c7"
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5a9e65",
   "metadata": {
    "id": "6c5a9e65"
   },
   "source": [
    "### Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9f3ee24",
   "metadata": {
    "id": "f9f3ee24"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef71e53e",
   "metadata": {
    "id": "ef71e53e"
   },
   "outputs": [],
   "source": [
    "train_datsgen=ImageDataGenerator(rescale=1/255,\n",
    "                                shear_range=0.2,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02552efd",
   "metadata": {
    "id": "02552efd"
   },
   "outputs": [],
   "source": [
    "test_datsgen=ImageDataGenerator(rescale=1/255,\n",
    "                               shear_range=0.2,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb924401",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bb924401",
    "outputId": "e7fb4d8c-228a-4b3a-efd0-f656a93aaa86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2214 images belonging to 51 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set=train_datsgen.flow_from_directory(r\"C:\\Users\\sndes\\JupyterProjects\\FinalProject\\Fin_DS - Copy\\train\",\n",
    "                                              target_size=(64, 64),\n",
    "                                              class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15fcef3c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "15fcef3c",
    "outputId": "bec4aa7b-ce7d-4c25-db1c-30fcd311adb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 600 images belonging to 51 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set=train_datsgen.flow_from_directory(r\"C:\\Users\\sndes\\JupyterProjects\\FinalProject\\Fin_DS - Copy\\val\",\n",
    "                                              target_size=(64, 64),\n",
    "                                              class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bfb590",
   "metadata": {
    "id": "81bfb590"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c90ca3a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0c90ca3a",
    "outputId": "a88f63ba-62dd-4336-d27d-56095196c06e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "70/70 [==============================] - 9s 105ms/step - loss: 3.9663 - accuracy: 0.0199\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 7s 105ms/step - loss: 3.8811 - accuracy: 0.0506\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 7s 103ms/step - loss: 3.6186 - accuracy: 0.1016\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 7s 104ms/step - loss: 3.2305 - accuracy: 0.1893\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 7s 102ms/step - loss: 2.7572 - accuracy: 0.2927\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 7s 101ms/step - loss: 2.2976 - accuracy: 0.4092\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 7s 99ms/step - loss: 1.8703 - accuracy: 0.5059\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 7s 98ms/step - loss: 1.4835 - accuracy: 0.6048\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 7s 101ms/step - loss: 1.2501 - accuracy: 0.6707\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 7s 99ms/step - loss: 1.0093 - accuracy: 0.7276\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 7s 102ms/step - loss: 0.8318 - accuracy: 0.7769\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 7s 100ms/step - loss: 0.7009 - accuracy: 0.8053\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 7s 101ms/step - loss: 0.6063 - accuracy: 0.8302\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 7s 101ms/step - loss: 0.5240 - accuracy: 0.8509\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 7s 106ms/step - loss: 0.4272 - accuracy: 0.8808\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 7s 98ms/step - loss: 0.3585 - accuracy: 0.8966\n",
      "Epoch 17/100\n",
      "70/70 [==============================] - 8s 109ms/step - loss: 0.3728 - accuracy: 0.8893\n",
      "Epoch 18/100\n",
      "70/70 [==============================] - 7s 102ms/step - loss: 0.3223 - accuracy: 0.9106\n",
      "Epoch 19/100\n",
      "70/70 [==============================] - 7s 105ms/step - loss: 0.2677 - accuracy: 0.9223\n",
      "Epoch 20/100\n",
      "70/70 [==============================] - 8s 106ms/step - loss: 0.2614 - accuracy: 0.9214\n",
      "Epoch 21/100\n",
      "70/70 [==============================] - 7s 104ms/step - loss: 0.2150 - accuracy: 0.9372\n",
      "Epoch 22/100\n",
      "70/70 [==============================] - 7s 100ms/step - loss: 0.2065 - accuracy: 0.9408\n",
      "Epoch 23/100\n",
      "70/70 [==============================] - 7s 98ms/step - loss: 0.2026 - accuracy: 0.9395\n",
      "Epoch 24/100\n",
      "70/70 [==============================] - 7s 103ms/step - loss: 0.1571 - accuracy: 0.9548\n",
      "Epoch 25/100\n",
      "70/70 [==============================] - 7s 102ms/step - loss: 0.1616 - accuracy: 0.9535\n",
      "Epoch 26/100\n",
      "70/70 [==============================] - 7s 102ms/step - loss: 0.1820 - accuracy: 0.9481\n",
      "Epoch 27/100\n",
      "70/70 [==============================] - 7s 104ms/step - loss: 0.1268 - accuracy: 0.9616\n",
      "Epoch 28/100\n",
      "70/70 [==============================] - 7s 100ms/step - loss: 0.1308 - accuracy: 0.9589\n",
      "Epoch 29/100\n",
      "70/70 [==============================] - 7s 100ms/step - loss: 0.1398 - accuracy: 0.9589\n",
      "Epoch 30/100\n",
      "70/70 [==============================] - 7s 103ms/step - loss: 0.1160 - accuracy: 0.9675\n",
      "Epoch 31/100\n",
      "70/70 [==============================] - 7s 100ms/step - loss: 0.1159 - accuracy: 0.9688\n",
      "Epoch 32/100\n",
      "70/70 [==============================] - 7s 105ms/step - loss: 0.1100 - accuracy: 0.9630\n",
      "Epoch 33/100\n",
      "70/70 [==============================] - 7s 104ms/step - loss: 0.0732 - accuracy: 0.9783\n",
      "Epoch 34/100\n",
      "70/70 [==============================] - 7s 99ms/step - loss: 0.0961 - accuracy: 0.9743\n",
      "Epoch 35/100\n",
      "70/70 [==============================] - 7s 98ms/step - loss: 0.0870 - accuracy: 0.9738\n",
      "Epoch 36/100\n",
      "70/70 [==============================] - 7s 103ms/step - loss: 0.1178 - accuracy: 0.9625\n",
      "Epoch 37/100\n",
      "70/70 [==============================] - 7s 99ms/step - loss: 0.1121 - accuracy: 0.9675\n",
      "Epoch 38/100\n",
      "70/70 [==============================] - 7s 98ms/step - loss: 0.0825 - accuracy: 0.9743\n",
      "Epoch 39/100\n",
      "70/70 [==============================] - 7s 100ms/step - loss: 0.1131 - accuracy: 0.9684\n",
      "Epoch 40/100\n",
      "70/70 [==============================] - 7s 103ms/step - loss: 0.0745 - accuracy: 0.9792\n",
      "Epoch 41/100\n",
      "70/70 [==============================] - 7s 102ms/step - loss: 0.1019 - accuracy: 0.9702\n",
      "Epoch 42/100\n",
      "70/70 [==============================] - 7s 103ms/step - loss: 0.0651 - accuracy: 0.9783\n",
      "Epoch 43/100\n",
      "70/70 [==============================] - 7s 102ms/step - loss: 0.0899 - accuracy: 0.9724\n",
      "Epoch 44/100\n",
      "70/70 [==============================] - 7s 95ms/step - loss: 0.0793 - accuracy: 0.9801\n",
      "Epoch 45/100\n",
      "70/70 [==============================] - 8s 108ms/step - loss: 0.0587 - accuracy: 0.9806\n",
      "Epoch 46/100\n",
      "70/70 [==============================] - 7s 104ms/step - loss: 0.0685 - accuracy: 0.9797\n",
      "Epoch 47/100\n",
      "70/70 [==============================] - 7s 98ms/step - loss: 0.0648 - accuracy: 0.9846\n",
      "Epoch 48/100\n",
      "70/70 [==============================] - 7s 102ms/step - loss: 0.0545 - accuracy: 0.9842\n",
      "Epoch 49/100\n",
      "70/70 [==============================] - 7s 99ms/step - loss: 0.0713 - accuracy: 0.9833\n",
      "Epoch 50/100\n",
      "70/70 [==============================] - 7s 101ms/step - loss: 0.0979 - accuracy: 0.9679\n",
      "Epoch 51/100\n",
      "70/70 [==============================] - 7s 100ms/step - loss: 0.0872 - accuracy: 0.9729\n",
      "Epoch 52/100\n",
      "70/70 [==============================] - 7s 105ms/step - loss: 0.0736 - accuracy: 0.9756\n",
      "Epoch 53/100\n",
      "70/70 [==============================] - 7s 105ms/step - loss: 0.0949 - accuracy: 0.9743\n",
      "Epoch 54/100\n",
      "70/70 [==============================] - 7s 102ms/step - loss: 0.0763 - accuracy: 0.9792\n",
      "Epoch 55/100\n",
      "70/70 [==============================] - 7s 102ms/step - loss: 0.0650 - accuracy: 0.9824\n",
      "Epoch 56/100\n",
      "70/70 [==============================] - 7s 106ms/step - loss: 0.0583 - accuracy: 0.9846\n",
      "Epoch 57/100\n",
      "70/70 [==============================] - 7s 102ms/step - loss: 0.0570 - accuracy: 0.9883\n",
      "Epoch 58/100\n",
      "70/70 [==============================] - 7s 101ms/step - loss: 0.0557 - accuracy: 0.9819\n",
      "Epoch 59/100\n",
      "70/70 [==============================] - 7s 99ms/step - loss: 0.0583 - accuracy: 0.9815\n",
      "Epoch 60/100\n",
      "70/70 [==============================] - 7s 102ms/step - loss: 0.0509 - accuracy: 0.9837\n",
      "Epoch 61/100\n",
      "70/70 [==============================] - 7s 104ms/step - loss: 0.0498 - accuracy: 0.9860\n",
      "Epoch 62/100\n",
      "70/70 [==============================] - 8s 108ms/step - loss: 0.0551 - accuracy: 0.9851\n",
      "Epoch 63/100\n",
      "70/70 [==============================] - 7s 104ms/step - loss: 0.0620 - accuracy: 0.9842\n",
      "Epoch 64/100\n",
      "70/70 [==============================] - 7s 101ms/step - loss: 0.0374 - accuracy: 0.9910\n",
      "Epoch 65/100\n",
      "70/70 [==============================] - 7s 101ms/step - loss: 0.0477 - accuracy: 0.9860\n",
      "Epoch 66/100\n",
      "70/70 [==============================] - 7s 101ms/step - loss: 0.0333 - accuracy: 0.9905\n",
      "Epoch 67/100\n",
      "70/70 [==============================] - 7s 105ms/step - loss: 0.0410 - accuracy: 0.9864\n",
      "Epoch 68/100\n",
      "70/70 [==============================] - 7s 100ms/step - loss: 0.0861 - accuracy: 0.9765\n",
      "Epoch 69/100\n",
      "70/70 [==============================] - 8s 107ms/step - loss: 0.0688 - accuracy: 0.9815\n",
      "Epoch 70/100\n",
      "70/70 [==============================] - 7s 103ms/step - loss: 0.0448 - accuracy: 0.9892\n",
      "Epoch 71/100\n",
      "70/70 [==============================] - 7s 101ms/step - loss: 0.0449 - accuracy: 0.9860\n",
      "Epoch 72/100\n",
      "70/70 [==============================] - 7s 103ms/step - loss: 0.0568 - accuracy: 0.9819\n",
      "Epoch 73/100\n",
      "70/70 [==============================] - 7s 103ms/step - loss: 0.0447 - accuracy: 0.9833\n",
      "Epoch 74/100\n",
      "70/70 [==============================] - 7s 99ms/step - loss: 0.0450 - accuracy: 0.9869\n",
      "Epoch 75/100\n",
      "70/70 [==============================] - 7s 99ms/step - loss: 0.0500 - accuracy: 0.9837\n",
      "Epoch 76/100\n",
      "70/70 [==============================] - 7s 101ms/step - loss: 0.0489 - accuracy: 0.9860\n",
      "Epoch 77/100\n",
      "70/70 [==============================] - 7s 100ms/step - loss: 0.0422 - accuracy: 0.9851\n",
      "Epoch 78/100\n",
      "70/70 [==============================] - 7s 101ms/step - loss: 0.0424 - accuracy: 0.9874\n",
      "Epoch 79/100\n",
      "70/70 [==============================] - 8s 110ms/step - loss: 0.0352 - accuracy: 0.9869\n",
      "Epoch 80/100\n",
      "70/70 [==============================] - 8s 108ms/step - loss: 0.0333 - accuracy: 0.9855\n",
      "Epoch 81/100\n",
      "70/70 [==============================] - 7s 102ms/step - loss: 0.0425 - accuracy: 0.9874\n",
      "Epoch 82/100\n",
      "70/70 [==============================] - 7s 104ms/step - loss: 0.0422 - accuracy: 0.9874\n",
      "Epoch 83/100\n",
      "70/70 [==============================] - 7s 102ms/step - loss: 0.0217 - accuracy: 0.9937\n",
      "Epoch 84/100\n",
      "70/70 [==============================] - 7s 104ms/step - loss: 0.0479 - accuracy: 0.9864\n",
      "Epoch 85/100\n",
      "70/70 [==============================] - 7s 101ms/step - loss: 0.0374 - accuracy: 0.9874\n",
      "Epoch 86/100\n",
      "70/70 [==============================] - 7s 102ms/step - loss: 0.0393 - accuracy: 0.9851\n",
      "Epoch 87/100\n",
      "70/70 [==============================] - 7s 104ms/step - loss: 0.0412 - accuracy: 0.9851\n",
      "Epoch 88/100\n",
      "70/70 [==============================] - 8s 110ms/step - loss: 0.0429 - accuracy: 0.9864\n",
      "Epoch 89/100\n",
      "70/70 [==============================] - 7s 101ms/step - loss: 0.0308 - accuracy: 0.9905\n",
      "Epoch 90/100\n",
      "70/70 [==============================] - 7s 103ms/step - loss: 0.0561 - accuracy: 0.9815\n",
      "Epoch 91/100\n",
      "70/70 [==============================] - 7s 101ms/step - loss: 0.0470 - accuracy: 0.9860\n",
      "Epoch 92/100\n",
      "70/70 [==============================] - 7s 99ms/step - loss: 0.0386 - accuracy: 0.9837\n",
      "Epoch 93/100\n",
      "70/70 [==============================] - 7s 101ms/step - loss: 0.0347 - accuracy: 0.9883\n",
      "Epoch 94/100\n",
      "70/70 [==============================] - 7s 99ms/step - loss: 0.0531 - accuracy: 0.9806\n",
      "Epoch 95/100\n",
      "70/70 [==============================] - 7s 101ms/step - loss: 0.0329 - accuracy: 0.9901\n",
      "Epoch 96/100\n",
      "70/70 [==============================] - 7s 98ms/step - loss: 0.0526 - accuracy: 0.9797\n",
      "Epoch 97/100\n",
      "70/70 [==============================] - 7s 101ms/step - loss: 0.0721 - accuracy: 0.9815\n",
      "Epoch 98/100\n",
      "70/70 [==============================] - 7s 99ms/step - loss: 0.0488 - accuracy: 0.9860\n",
      "Epoch 99/100\n",
      "70/70 [==============================] - 7s 100ms/step - loss: 0.0370 - accuracy: 0.9887\n",
      "Epoch 100/100\n",
      "70/70 [==============================] - 7s 103ms/step - loss: 0.0222 - accuracy: 0.9941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x182ab7df310>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_set, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c533f745",
   "metadata": {
    "id": "c533f745"
   },
   "source": [
    "### Evaluate on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f34ceeb8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f34ceeb8",
    "outputId": "d38c08d3-cd13-4e67-8547-438f2fb093e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 3s 152ms/step - loss: 1.0838 - accuracy: 0.8767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.083763837814331, 0.8766666650772095]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423fe209",
   "metadata": {
    "id": "423fe209"
   },
   "source": [
    "### Prediction on sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e36876f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "id": "8e36876f",
    "outputId": "fa773fbb-fd0e-4e0c-e3e6-522df3c04dc0"
   },
   "outputs": [],
   "source": [
    "test_image=load_img(r\"C:\\Users\\sndes\\JupyterProjects\\FinalProject\\Fin_DS\\val\\न\\1_न_horizontal_flip.jpg\",target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a4f1e29",
   "metadata": {
    "id": "7a4f1e29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x182ae011490>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a3611ce",
   "metadata": {
    "id": "8a3611ce"
   },
   "outputs": [],
   "source": [
    "test_image=img_to_array(test_image)\n",
    "test_image=np.expand_dims(test_image,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10bd2180",
   "metadata": {
    "id": "10bd2180"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 64, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8954e14",
   "metadata": {
    "id": "e8954e14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'अ': 0,\n",
       " 'अं': 1,\n",
       " 'अः': 2,\n",
       " 'आ': 3,\n",
       " 'इ': 4,\n",
       " 'ई': 5,\n",
       " 'उ': 6,\n",
       " 'ऊ': 7,\n",
       " 'ऋ': 8,\n",
       " 'ए': 9,\n",
       " 'ऐ': 10,\n",
       " 'ओ': 11,\n",
       " 'औ': 12,\n",
       " 'क': 13,\n",
       " 'क्ष': 14,\n",
       " 'ख': 15,\n",
       " 'ग': 16,\n",
       " 'घ': 17,\n",
       " 'ङ': 18,\n",
       " 'च': 19,\n",
       " 'छ': 20,\n",
       " 'ज': 21,\n",
       " 'ज्ञ': 22,\n",
       " 'झ': 23,\n",
       " 'ञ': 24,\n",
       " 'ट': 25,\n",
       " 'ठ': 26,\n",
       " 'ड': 27,\n",
       " 'ढ': 28,\n",
       " 'ण': 29,\n",
       " 'त': 30,\n",
       " 'त्र': 31,\n",
       " 'थ': 32,\n",
       " 'द': 33,\n",
       " 'ध': 34,\n",
       " 'न': 35,\n",
       " 'प': 36,\n",
       " 'फ': 37,\n",
       " 'ब': 38,\n",
       " 'भ': 39,\n",
       " 'म': 40,\n",
       " 'य': 41,\n",
       " 'र': 42,\n",
       " 'ल': 43,\n",
       " 'ळ': 44,\n",
       " 'व': 45,\n",
       " 'श': 46,\n",
       " 'श्र': 47,\n",
       " 'ष': 48,\n",
       " 'स': 49,\n",
       " 'ह': 50}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7807a4a6",
   "metadata": {
    "id": "7807a4a6"
   },
   "outputs": [],
   "source": [
    "indices = training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0405012c",
   "metadata": {
    "id": "0405012c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "न\n"
     ]
    }
   ],
   "source": [
    "result = np.argmax(model.predict(test_image,verbose=False))\n",
    "print(list(indices.keys())[list(indices.values()).index(result)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af0c0e6",
   "metadata": {
    "id": "b1dc236e"
   },
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "08e4c3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=load_img(r\"C:\\Users\\sndes\\JupyterProjects\\FinalProject\\1212.jpg\",target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "03eb7e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=img_to_array(x)\n",
    "x=np.expand_dims(x,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1afe1359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ठ\n"
     ]
    }
   ],
   "source": [
    "result = np.argmax(model.predict(x,verbose=False))\n",
    "print(list(indices.keys())[list(indices.values()).index(result)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afec1e2",
   "metadata": {},
   "source": [
    "### Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a79498ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 2, 2, 512)         14714688  \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 512)               1049088   \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 51)                26163     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15789939 (60.23 MB)\n",
      "Trainable params: 1075251 (4.10 MB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "70/70 [==============================] - 18s 256ms/step - loss: 3.8210 - accuracy: 0.0732 - val_loss: 3.4389 - val_accuracy: 0.1250\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 20s 290ms/step - loss: 3.1880 - accuracy: 0.1752 - val_loss: 2.9238 - val_accuracy: 0.2317\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 22s 310ms/step - loss: 2.7480 - accuracy: 0.2638 - val_loss: 2.4811 - val_accuracy: 0.3067\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 21s 302ms/step - loss: 2.3992 - accuracy: 0.3577 - val_loss: 2.2639 - val_accuracy: 0.3717\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 21s 304ms/step - loss: 2.1672 - accuracy: 0.4006 - val_loss: 2.0463 - val_accuracy: 0.4250\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 20s 288ms/step - loss: 2.0124 - accuracy: 0.4273 - val_loss: 1.9244 - val_accuracy: 0.4383\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 21s 294ms/step - loss: 1.8591 - accuracy: 0.4765 - val_loss: 1.8020 - val_accuracy: 0.4883\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 22s 317ms/step - loss: 1.7561 - accuracy: 0.5041 - val_loss: 1.7400 - val_accuracy: 0.4867\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 22s 312ms/step - loss: 1.6555 - accuracy: 0.5330 - val_loss: 1.6267 - val_accuracy: 0.5183\n",
      "Epoch 10/100\n",
      "40/70 [================>.............] - ETA: 7s - loss: 1.6208 - accuracy: 0.5311"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 33\u001b[0m\n\u001b[0;32m     28\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     29\u001b[0m               optimizer\u001b[38;5;241m=\u001b[39mAdam(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m),  \u001b[38;5;66;03m# You can adjust the learning rate\u001b[39;00m\n\u001b[0;32m     30\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(training_set, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39mtest_set)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Evaluate on unseen data\u001b[39;00m\n\u001b[0;32m     36\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate(test_set)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    868\u001b[0m       args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_config\n\u001b[0;32m    869\u001b[0m   )\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mflat_call(args)\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    256\u001b[0m     )\n\u001b[0;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1480\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1481\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1482\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1483\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1484\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1485\u001b[0m   )\n\u001b[0;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Load the pre-trained VGG16 model without the top (fully connected) layers\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
    "\n",
    "# Freeze the layers of the pre-trained model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create a new model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the pre-trained VGG16 model\n",
    "model.add(base_model)\n",
    "\n",
    "# Add your own classifier on top\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(51, activation='softmax'))\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.0001),  # You can adjust the learning rate\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(training_set, epochs=100, validation_data=test_set)\n",
    "\n",
    "# Evaluate on unseen data\n",
    "model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a94b7ba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Func  (None, 2, 2, 1280)        2257984   \n",
      " tional)                                                         \n",
      "                                                                 \n",
      " global_average_pooling2d_3  (None, 1280)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 512)               655872    \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 51)                26163     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2940019 (11.22 MB)\n",
      "Trainable params: 682035 (2.60 MB)\n",
      "Non-trainable params: 2257984 (8.61 MB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "70/70 [==============================] - 16s 150ms/step - loss: 3.6053 - accuracy: 0.1165 - val_loss: 2.9007 - val_accuracy: 0.2533\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 8s 116ms/step - loss: 2.8449 - accuracy: 0.2448 - val_loss: 2.5840 - val_accuracy: 0.3283\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 9s 122ms/step - loss: 2.4528 - accuracy: 0.3388 - val_loss: 2.3611 - val_accuracy: 0.3633\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 9s 123ms/step - loss: 2.2825 - accuracy: 0.3853 - val_loss: 2.1145 - val_accuracy: 0.4267\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 8s 115ms/step - loss: 2.0409 - accuracy: 0.4372 - val_loss: 2.0277 - val_accuracy: 0.4317\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 8s 115ms/step - loss: 1.9417 - accuracy: 0.4544 - val_loss: 1.9553 - val_accuracy: 0.4550\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 8s 112ms/step - loss: 1.8092 - accuracy: 0.4991 - val_loss: 1.9012 - val_accuracy: 0.4467\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 8s 120ms/step - loss: 1.7478 - accuracy: 0.5050 - val_loss: 1.8589 - val_accuracy: 0.4833\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 8s 120ms/step - loss: 1.6023 - accuracy: 0.5488 - val_loss: 1.7829 - val_accuracy: 0.5050\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 8s 117ms/step - loss: 1.5989 - accuracy: 0.5470 - val_loss: 1.6953 - val_accuracy: 0.4867\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 9s 122ms/step - loss: 1.5080 - accuracy: 0.5637 - val_loss: 1.5924 - val_accuracy: 0.5417\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 9s 122ms/step - loss: 1.4411 - accuracy: 0.5903 - val_loss: 1.5095 - val_accuracy: 0.5883\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 8s 120ms/step - loss: 1.4000 - accuracy: 0.5980 - val_loss: 1.5180 - val_accuracy: 0.5683\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 9s 125ms/step - loss: 1.3892 - accuracy: 0.5953 - val_loss: 1.5443 - val_accuracy: 0.5517\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 8s 116ms/step - loss: 1.3053 - accuracy: 0.6247 - val_loss: 1.5174 - val_accuracy: 0.5733\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 8s 120ms/step - loss: 1.2708 - accuracy: 0.6215 - val_loss: 1.4430 - val_accuracy: 0.5800\n",
      "Epoch 17/100\n",
      "70/70 [==============================] - 9s 135ms/step - loss: 1.2269 - accuracy: 0.6463 - val_loss: 1.4103 - val_accuracy: 0.5917\n",
      "Epoch 18/100\n",
      "70/70 [==============================] - 12s 168ms/step - loss: 1.2091 - accuracy: 0.6477 - val_loss: 1.3410 - val_accuracy: 0.6117\n",
      "Epoch 19/100\n",
      "70/70 [==============================] - 12s 164ms/step - loss: 1.1705 - accuracy: 0.6527 - val_loss: 1.4812 - val_accuracy: 0.5700\n",
      "Epoch 20/100\n",
      "70/70 [==============================] - 11s 160ms/step - loss: 1.1382 - accuracy: 0.6734 - val_loss: 1.3328 - val_accuracy: 0.5900\n",
      "Epoch 21/100\n",
      "70/70 [==============================] - 11s 161ms/step - loss: 1.0960 - accuracy: 0.6847 - val_loss: 1.5350 - val_accuracy: 0.5650\n",
      "Epoch 22/100\n",
      "70/70 [==============================] - 12s 164ms/step - loss: 1.0367 - accuracy: 0.7001 - val_loss: 1.3003 - val_accuracy: 0.6067\n",
      "Epoch 23/100\n",
      "70/70 [==============================] - 12s 166ms/step - loss: 1.0652 - accuracy: 0.6965 - val_loss: 1.2519 - val_accuracy: 0.6150\n",
      "Epoch 24/100\n",
      "70/70 [==============================] - 11s 161ms/step - loss: 1.0218 - accuracy: 0.6974 - val_loss: 1.2944 - val_accuracy: 0.6517\n",
      "Epoch 25/100\n",
      "70/70 [==============================] - 11s 157ms/step - loss: 0.9587 - accuracy: 0.7236 - val_loss: 1.2513 - val_accuracy: 0.6383\n",
      "Epoch 26/100\n",
      "70/70 [==============================] - 11s 160ms/step - loss: 1.0023 - accuracy: 0.7014 - val_loss: 1.2922 - val_accuracy: 0.6383\n",
      "Epoch 27/100\n",
      "70/70 [==============================] - 11s 164ms/step - loss: 0.9738 - accuracy: 0.7186 - val_loss: 1.2864 - val_accuracy: 0.6250\n",
      "Epoch 28/100\n",
      "70/70 [==============================] - 11s 161ms/step - loss: 0.9333 - accuracy: 0.7281 - val_loss: 1.1851 - val_accuracy: 0.6583\n",
      "Epoch 29/100\n",
      "70/70 [==============================] - 11s 163ms/step - loss: 0.8852 - accuracy: 0.7421 - val_loss: 1.2918 - val_accuracy: 0.6500\n",
      "Epoch 30/100\n",
      "70/70 [==============================] - 12s 167ms/step - loss: 0.8751 - accuracy: 0.7376 - val_loss: 1.0987 - val_accuracy: 0.6833\n",
      "Epoch 31/100\n",
      "70/70 [==============================] - 11s 160ms/step - loss: 0.8877 - accuracy: 0.7421 - val_loss: 1.1918 - val_accuracy: 0.6600\n",
      "Epoch 32/100\n",
      "70/70 [==============================] - 11s 160ms/step - loss: 0.8234 - accuracy: 0.7602 - val_loss: 1.0818 - val_accuracy: 0.6800\n",
      "Epoch 33/100\n",
      "70/70 [==============================] - 11s 161ms/step - loss: 0.8646 - accuracy: 0.7484 - val_loss: 1.1126 - val_accuracy: 0.6883\n",
      "Epoch 34/100\n",
      "70/70 [==============================] - 11s 156ms/step - loss: 0.8340 - accuracy: 0.7575 - val_loss: 1.1118 - val_accuracy: 0.6850\n",
      "Epoch 35/100\n",
      "70/70 [==============================] - 11s 159ms/step - loss: 0.7748 - accuracy: 0.7683 - val_loss: 1.1123 - val_accuracy: 0.7133\n",
      "Epoch 36/100\n",
      "70/70 [==============================] - 12s 167ms/step - loss: 0.8016 - accuracy: 0.7575 - val_loss: 1.1378 - val_accuracy: 0.6767\n",
      "Epoch 37/100\n",
      "70/70 [==============================] - 11s 158ms/step - loss: 0.7733 - accuracy: 0.7796 - val_loss: 1.0516 - val_accuracy: 0.6967\n",
      "Epoch 38/100\n",
      "70/70 [==============================] - 11s 163ms/step - loss: 0.7874 - accuracy: 0.7593 - val_loss: 1.1294 - val_accuracy: 0.6700\n",
      "Epoch 39/100\n",
      "70/70 [==============================] - 12s 165ms/step - loss: 0.7534 - accuracy: 0.7678 - val_loss: 1.0635 - val_accuracy: 0.6867\n",
      "Epoch 40/100\n",
      "70/70 [==============================] - 12s 165ms/step - loss: 0.7544 - accuracy: 0.7593 - val_loss: 1.1233 - val_accuracy: 0.6933\n",
      "Epoch 41/100\n",
      "70/70 [==============================] - 11s 160ms/step - loss: 0.7359 - accuracy: 0.7922 - val_loss: 1.1783 - val_accuracy: 0.6867\n",
      "Epoch 42/100\n",
      "70/70 [==============================] - 12s 167ms/step - loss: 0.7393 - accuracy: 0.7755 - val_loss: 1.0726 - val_accuracy: 0.7033\n",
      "Epoch 43/100\n",
      "70/70 [==============================] - 11s 155ms/step - loss: 0.7373 - accuracy: 0.7796 - val_loss: 1.0489 - val_accuracy: 0.7067\n",
      "Epoch 44/100\n",
      "70/70 [==============================] - 11s 152ms/step - loss: 0.7663 - accuracy: 0.7773 - val_loss: 1.0487 - val_accuracy: 0.7117\n",
      "Epoch 45/100\n",
      "70/70 [==============================] - 11s 157ms/step - loss: 0.6607 - accuracy: 0.8044 - val_loss: 1.0414 - val_accuracy: 0.7300\n",
      "Epoch 46/100\n",
      "70/70 [==============================] - 11s 163ms/step - loss: 0.6673 - accuracy: 0.8076 - val_loss: 0.9952 - val_accuracy: 0.7383\n",
      "Epoch 47/100\n",
      "70/70 [==============================] - 12s 166ms/step - loss: 0.6678 - accuracy: 0.7981 - val_loss: 0.9771 - val_accuracy: 0.7233\n",
      "Epoch 48/100\n",
      "70/70 [==============================] - 11s 157ms/step - loss: 0.6411 - accuracy: 0.8126 - val_loss: 1.0058 - val_accuracy: 0.7100\n",
      "Epoch 49/100\n",
      "70/70 [==============================] - 12s 164ms/step - loss: 0.6394 - accuracy: 0.8103 - val_loss: 1.1289 - val_accuracy: 0.7167\n",
      "Epoch 50/100\n",
      "70/70 [==============================] - 11s 163ms/step - loss: 0.6627 - accuracy: 0.8017 - val_loss: 0.9600 - val_accuracy: 0.7100\n",
      "Epoch 51/100\n",
      "70/70 [==============================] - 12s 167ms/step - loss: 0.6197 - accuracy: 0.8121 - val_loss: 1.0876 - val_accuracy: 0.7150\n",
      "Epoch 52/100\n",
      "70/70 [==============================] - 11s 158ms/step - loss: 0.6534 - accuracy: 0.7977 - val_loss: 1.0234 - val_accuracy: 0.7317\n",
      "Epoch 53/100\n",
      "70/70 [==============================] - 11s 155ms/step - loss: 0.6046 - accuracy: 0.8126 - val_loss: 1.0383 - val_accuracy: 0.7050\n",
      "Epoch 54/100\n",
      "70/70 [==============================] - 11s 158ms/step - loss: 0.5695 - accuracy: 0.8320 - val_loss: 0.9844 - val_accuracy: 0.7183\n",
      "Epoch 55/100\n",
      "70/70 [==============================] - 11s 156ms/step - loss: 0.6061 - accuracy: 0.8144 - val_loss: 0.9993 - val_accuracy: 0.7367\n",
      "Epoch 56/100\n",
      "70/70 [==============================] - 11s 157ms/step - loss: 0.5757 - accuracy: 0.8324 - val_loss: 0.9709 - val_accuracy: 0.7383\n",
      "Epoch 57/100\n",
      "70/70 [==============================] - 11s 165ms/step - loss: 0.5503 - accuracy: 0.8437 - val_loss: 0.8772 - val_accuracy: 0.7600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "70/70 [==============================] - 11s 158ms/step - loss: 0.5518 - accuracy: 0.8266 - val_loss: 0.9464 - val_accuracy: 0.7333\n",
      "Epoch 59/100\n",
      "70/70 [==============================] - 11s 160ms/step - loss: 0.5777 - accuracy: 0.8198 - val_loss: 1.0584 - val_accuracy: 0.7117\n",
      "Epoch 60/100\n",
      "70/70 [==============================] - 11s 160ms/step - loss: 0.6008 - accuracy: 0.8216 - val_loss: 1.0303 - val_accuracy: 0.7233\n",
      "Epoch 61/100\n",
      "70/70 [==============================] - 11s 158ms/step - loss: 0.5834 - accuracy: 0.8225 - val_loss: 0.8705 - val_accuracy: 0.7750\n",
      "Epoch 62/100\n",
      "70/70 [==============================] - 11s 154ms/step - loss: 0.5207 - accuracy: 0.8523 - val_loss: 0.9092 - val_accuracy: 0.7750\n",
      "Epoch 63/100\n",
      "70/70 [==============================] - 11s 153ms/step - loss: 0.5267 - accuracy: 0.8478 - val_loss: 0.9540 - val_accuracy: 0.7267\n",
      "Epoch 64/100\n",
      "70/70 [==============================] - 11s 155ms/step - loss: 0.5071 - accuracy: 0.8519 - val_loss: 1.0079 - val_accuracy: 0.7467\n",
      "Epoch 65/100\n",
      "70/70 [==============================] - 12s 167ms/step - loss: 0.5297 - accuracy: 0.8455 - val_loss: 0.8925 - val_accuracy: 0.7767\n",
      "Epoch 66/100\n",
      "70/70 [==============================] - 11s 154ms/step - loss: 0.5379 - accuracy: 0.8369 - val_loss: 0.9418 - val_accuracy: 0.7433\n",
      "Epoch 67/100\n",
      "70/70 [==============================] - 11s 158ms/step - loss: 0.4989 - accuracy: 0.8478 - val_loss: 0.8546 - val_accuracy: 0.7600\n",
      "Epoch 68/100\n",
      "70/70 [==============================] - 11s 160ms/step - loss: 0.4563 - accuracy: 0.8681 - val_loss: 0.9660 - val_accuracy: 0.7517\n",
      "Epoch 69/100\n",
      "70/70 [==============================] - 11s 159ms/step - loss: 0.4644 - accuracy: 0.8473 - val_loss: 0.9085 - val_accuracy: 0.7583\n",
      "Epoch 70/100\n",
      "70/70 [==============================] - 11s 159ms/step - loss: 0.4975 - accuracy: 0.8505 - val_loss: 0.9087 - val_accuracy: 0.7600\n",
      "Epoch 71/100\n",
      "70/70 [==============================] - 11s 160ms/step - loss: 0.4968 - accuracy: 0.8519 - val_loss: 0.8925 - val_accuracy: 0.7917\n",
      "Epoch 72/100\n",
      "70/70 [==============================] - 11s 153ms/step - loss: 0.4498 - accuracy: 0.8713 - val_loss: 0.9234 - val_accuracy: 0.7667\n",
      "Epoch 73/100\n",
      "70/70 [==============================] - 11s 151ms/step - loss: 0.4611 - accuracy: 0.8622 - val_loss: 0.9211 - val_accuracy: 0.7650\n",
      "Epoch 74/100\n",
      "70/70 [==============================] - 11s 163ms/step - loss: 0.4743 - accuracy: 0.8519 - val_loss: 0.9897 - val_accuracy: 0.7583\n",
      "Epoch 75/100\n",
      "70/70 [==============================] - 11s 157ms/step - loss: 0.4599 - accuracy: 0.8604 - val_loss: 0.9701 - val_accuracy: 0.7450\n",
      "Epoch 76/100\n",
      "70/70 [==============================] - 11s 159ms/step - loss: 0.4289 - accuracy: 0.8713 - val_loss: 0.8965 - val_accuracy: 0.7783\n",
      "Epoch 77/100\n",
      "70/70 [==============================] - 11s 162ms/step - loss: 0.4803 - accuracy: 0.8591 - val_loss: 0.8471 - val_accuracy: 0.7850\n",
      "Epoch 78/100\n",
      "70/70 [==============================] - 11s 161ms/step - loss: 0.4797 - accuracy: 0.8532 - val_loss: 0.8941 - val_accuracy: 0.7900\n",
      "Epoch 79/100\n",
      "70/70 [==============================] - 11s 162ms/step - loss: 0.4494 - accuracy: 0.8668 - val_loss: 0.8594 - val_accuracy: 0.7767\n",
      "Epoch 80/100\n",
      "70/70 [==============================] - 12s 164ms/step - loss: 0.4203 - accuracy: 0.8740 - val_loss: 0.8855 - val_accuracy: 0.7717\n",
      "Epoch 81/100\n",
      "70/70 [==============================] - 11s 152ms/step - loss: 0.4131 - accuracy: 0.8776 - val_loss: 0.8835 - val_accuracy: 0.7733\n",
      "Epoch 82/100\n",
      "70/70 [==============================] - 11s 153ms/step - loss: 0.3918 - accuracy: 0.8875 - val_loss: 1.0001 - val_accuracy: 0.7517\n",
      "Epoch 83/100\n",
      "70/70 [==============================] - 11s 160ms/step - loss: 0.4289 - accuracy: 0.8636 - val_loss: 0.8391 - val_accuracy: 0.7833\n",
      "Epoch 84/100\n",
      "70/70 [==============================] - 11s 162ms/step - loss: 0.4325 - accuracy: 0.8722 - val_loss: 0.8407 - val_accuracy: 0.8067\n",
      "Epoch 85/100\n",
      "70/70 [==============================] - 11s 157ms/step - loss: 0.3922 - accuracy: 0.8848 - val_loss: 0.9103 - val_accuracy: 0.7867\n",
      "Epoch 86/100\n",
      "70/70 [==============================] - 11s 160ms/step - loss: 0.3880 - accuracy: 0.8839 - val_loss: 0.9127 - val_accuracy: 0.7483\n",
      "Epoch 87/100\n",
      "70/70 [==============================] - 11s 160ms/step - loss: 0.4466 - accuracy: 0.8650 - val_loss: 0.8724 - val_accuracy: 0.7650\n",
      "Epoch 88/100\n",
      "70/70 [==============================] - 11s 158ms/step - loss: 0.3915 - accuracy: 0.8767 - val_loss: 0.8500 - val_accuracy: 0.7883\n",
      "Epoch 89/100\n",
      "70/70 [==============================] - 11s 162ms/step - loss: 0.4067 - accuracy: 0.8749 - val_loss: 0.7993 - val_accuracy: 0.7900\n",
      "Epoch 90/100\n",
      "70/70 [==============================] - 11s 155ms/step - loss: 0.3980 - accuracy: 0.8780 - val_loss: 0.8687 - val_accuracy: 0.7633\n",
      "Epoch 91/100\n",
      "70/70 [==============================] - 11s 152ms/step - loss: 0.3947 - accuracy: 0.8744 - val_loss: 0.8322 - val_accuracy: 0.7833\n",
      "Epoch 92/100\n",
      "70/70 [==============================] - 11s 150ms/step - loss: 0.3921 - accuracy: 0.8780 - val_loss: 0.9306 - val_accuracy: 0.7817\n",
      "Epoch 93/100\n",
      "70/70 [==============================] - 11s 160ms/step - loss: 0.4155 - accuracy: 0.8699 - val_loss: 0.8346 - val_accuracy: 0.7867\n",
      "Epoch 94/100\n",
      "70/70 [==============================] - 11s 159ms/step - loss: 0.3843 - accuracy: 0.8794 - val_loss: 0.9265 - val_accuracy: 0.7700\n",
      "Epoch 95/100\n",
      "70/70 [==============================] - 11s 162ms/step - loss: 0.4030 - accuracy: 0.8740 - val_loss: 0.9187 - val_accuracy: 0.7850\n",
      "Epoch 96/100\n",
      "70/70 [==============================] - 11s 159ms/step - loss: 0.3869 - accuracy: 0.8862 - val_loss: 0.8136 - val_accuracy: 0.7917\n",
      "Epoch 97/100\n",
      "70/70 [==============================] - 12s 164ms/step - loss: 0.4095 - accuracy: 0.8767 - val_loss: 0.8400 - val_accuracy: 0.7900\n",
      "Epoch 98/100\n",
      "70/70 [==============================] - 11s 160ms/step - loss: 0.4212 - accuracy: 0.8722 - val_loss: 0.9008 - val_accuracy: 0.7850\n",
      "Epoch 99/100\n",
      "70/70 [==============================] - 11s 159ms/step - loss: 0.3991 - accuracy: 0.8749 - val_loss: 0.9340 - val_accuracy: 0.7767\n",
      "Epoch 100/100\n",
      "70/70 [==============================] - 11s 151ms/step - loss: 0.3327 - accuracy: 0.8948 - val_loss: 0.8446 - val_accuracy: 0.7817\n",
      "19/19 [==============================] - 2s 114ms/step - loss: 0.8439 - accuracy: 0.7950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8439109921455383, 0.7950000166893005]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.applications import MobileNetV2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Load the pre-trained MobileNetV2 model without the top (fully connected) layers\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
    "\n",
    "# Freeze the layers of the pre-trained model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create a new model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the pre-trained MobileNetV2 model\n",
    "model.add(base_model)\n",
    "\n",
    "# Add Global Average Pooling 2D layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Add your own classifier on top\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(51, activation='softmax'))\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(training_set, epochs=100, validation_data=test_set)\n",
    "\n",
    "# Evaluate on unseen data\n",
    "model.evaluate(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172ca494",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
